# -*- coding: utf-8 -*-
"""NLP-Module 2-tokenization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x4FUIpI7yTDwPJMEV3GvkwF0KCFX9NkV
"""

import nltk
nltk.download('punkt_tab')
#from nltk.tokenize import (TreebankWordTokenizer, word_tokenize, wordpunct_tokenize, TweetTokenizer, MWETokenizer, sent_tokenize)
sentence = "It’s true, Ms. Lakshmi Sevukamaorthy is great, #Great"
sent_tokenize(sentence)

tokenizer = nltk.data.load('tokenizers/punkt/PY3/english.pickle')
tokenizer.tokenize(sentence)

word_tokenize(sentence)

# WHITESPACE tokenization
print(f'Whitespace tokenization = {sentence.split()}')

#PUNCTUATION tokenization
print(f'Punctuation-based tokenization = {wordpunct_tokenize(sentence)}')

# Default/TreebankWordTokenizer – regular expressions
tokenizer = TreebankWordTokenizer()
print(f'Default/Treebank tokenization = {tokenizer.tokenize(sentence)}')

# TWEET Tokenizer
tokenizer = TweetTokenizer()
print(f'Tweet-rules based  tokenization = {tokenizer.tokenize(sentence)}')

# MWE Tokenizer
tokenizer = MWETokenizer()
tokenizer.add_mwe(('Lakshmi', 'Sevukamoorthy'))
print(f'Multi-word expression(MWE)  tokenization = {tokenizer.tokenize(word_tokenize(sentence))}')
